{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Investigating textual similarities between Homer and Plato's collected works\n",
    "\n",
    "part 1 contains preprocessing and bi/trigram comparison"
   ],
   "id": "2cf8bf43a75808a6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Set up",
   "id": "5675cb405310e816"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import stanza\n",
    "from pathlib import Path\n",
    "from nltk.tokenize.punkt import PunktLanguageVars\n",
    "from nltk.util import bigrams\n",
    "from nltk.util import trigrams\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "import numpy\n",
    "from collections import Counter\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ],
   "id": "b8de12cb7369b85d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "nltk.download('punkt')",
   "id": "90e1806b0821c3ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Global Variables",
   "id": "fd12e8a89b8a51b"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "path_iliad = 'Homer (0012) - Iliad (001).xml'\n",
    "path_odyssey = 'Homer (0012) - Odyssey (002).xml'\n",
    "text_folder = Path('Text_Data/')\n",
    "lemmatized_folder = Path('Lemmatized_Data/')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Let's preprocess our data",
   "id": "d63e558e576031e7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# For Homer, we extract the already existing Lemmata",
   "id": "c10e8cc0b2274f2e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "stopwords = [\n",
    "    \"μή\", \"ἑαυτοῦ\", \"ἄν\", \"ἀλλ'\", \"ἀλλά\", \"ἄλλος\", \"ἀπό\", \"ἄρα\", \"αὐτός\", \"δ'\", \n",
    "    \"δέ\", \"δή\", \"διά\", \"δαί\", \"δαίς\", \"ἔτι\", \"ἐγώ\", \"ἐκ\", \"ἐμός\", \"ἐν\", \n",
    "    \"ἐπί\", \"εἰ\", \"εἰμί\", \"εἴμι\", \"εἰς\", \"γάρ\", \"γε\", \"γα\", \"ἡ\", \"ἤ\", \n",
    "    \"καί\", \"κατά\", \"μέν\", \"μετά\", \"μή\", \"ὁ\", \"ὅδε\", \"ὅς\", \"ὅστις\", \"ὅτι\", \n",
    "    \"οὕτως\", \"οὗτος\", \"οὔτε\", \"οὖν\", \"οὐδείς\", \"οἱ\", \"οὐ\", \"οὐδέ\", \"οὐκ\", \"περί\", \n",
    "    \"πρός\", \"σύ\", \"σύν\", \"τά\", \"τε\", \"τήν\", \"τῆς\", \"τῇ\", \"τι\", \"τί\", \n",
    "    \"τις\", \"τίς\", \"τό\", \"τοί\", \"τοιοῦτος\", \"τόν\", \"τούς\", \"τοῦ\", \"τῶν\", \"τῷ\", \n",
    "    \"ὑμός\", \"ὑπέρ\", \"ὑπό\", \"ὡς\", \"ὦ\", \"ὥστε\", \"ἐάν\", \"παρά\", \"σός\"\n",
    "]"
   ],
   "id": "a570f70f1589c82f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tree = ET.parse(path_iliad)\n",
    "root = tree.getroot()\n",
    "\n",
    "lemmatized_iliad = []\n",
    "for sentence in root.findall(\".//body/sentence\"):\n",
    "    if sentence is not None:\n",
    "        for child in sentence:\n",
    "            if child.tag == \"word\":\n",
    "                lemma = child.find(\"lemma\")\n",
    "                if lemma is not None and lemma.get(\"id\") != \"unknown\":\n",
    "                    word = lemma.get(\"entry\")\n",
    "                    if word not in stopwords:\n",
    "                        lemmatized_iliad.append(word)\n",
    "            elif child.tag == \"punct\":\n",
    "                mark = child.get(\"mark\")\n",
    "                if mark is not None and mark not in \",—᾽'\":\n",
    "                    lemmatized_iliad.append(child.get(\"mark\"))\n",
    "with open('Iliad_lemmatized.txt', 'w', encoding=\"utf-8\") as f:\n",
    "        f.write(\" \".join(lemmatized_iliad))"
   ],
   "id": "8f3201da226ae266",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tree = ET.parse(path_odyssey)\n",
    "root = tree.getroot()\n",
    "\n",
    "lemmatized_odyssey = []\n",
    "for sentence in root.findall(\".//body/sentence\"):\n",
    "    if sentence is not None:\n",
    "        for child in sentence:\n",
    "            if child.tag == \"word\":\n",
    "                lemma = child.find(\"lemma\")\n",
    "                if lemma is not None and lemma.get(\"id\") != \"unknown\":\n",
    "                    word = lemma.get(\"entry\")\n",
    "                    if word not in stopwords:\n",
    "                        lemmatized_odyssey.append(word)\n",
    "            elif child.tag == \"punct\":\n",
    "                mark = child.get(\"mark\")\n",
    "                if mark is not None and mark not in \",—᾽'\":\n",
    "                    lemmatized_odyssey.append(child.get(\"mark\"))\n",
    "        \n",
    "with open('Odyssey_lemmatized.txt', 'w', encoding=\"utf-8\") as f:\n",
    "        f.write(\" \".join(lemmatized_odyssey))"
   ],
   "id": "6cab5355a62f0e8e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# For Platos Works, we use a Lemmatizer",
   "id": "f164459085ef11db"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For the processing of Ancient Greek I rely on the Stanza package as documented on https://stanfordnlp.github.io/stanza/ ",
   "id": "dad5a0a52e8ce64e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "nlp = stanza.Pipeline('grc', processors='tokenize, lemma')",
   "id": "745fff759ee9c817",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def lemmatize_texts(text):\n",
    "    \"\"\"\n",
    "    lemmatizes a piece of text. Punctuation and stopwords are removed.\n",
    "    :param text: str, text\n",
    "    :return: str, lemmatized text\n",
    "    \"\"\"\n",
    "    lemmatized_data = nlp(text)\n",
    "    lemmatized_text = []\n",
    "    for sentence in lemmatized_data.sentences:\n",
    "        for word in sentence.words:\n",
    "            if not word.lemma in \",—᾽'\" and not word.lemma in stopwords:\n",
    "                lemmatized_text.append(word.lemma)\n",
    "    return \" \".join(lemmatized_text)\n",
    "        "
   ],
   "id": "71acaa211313af8d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "texts = []\n",
    "texts.extend(sorted(list(text_folder.glob('*'))))\n",
    "\n",
    "for text_file in texts:\n",
    "    with open(text_file, 'r', encoding=\"utf-8\") as f:\n",
    "        t = f.read()\n",
    "    l_t = lemmatize_texts(t)\n",
    "    with open(lemmatized_folder / text_file.name, 'w', encoding=\"utf-8\") as f:\n",
    "        f.write(l_t)"
   ],
   "id": "8d4c6c15a9ace1d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Let's start our Comparison",
   "id": "a65253b26f88e34f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Let's load our preprocessed data",
   "id": "6d482f44942c1fb5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with open('Iliad_lemmatized.txt', 'r', encoding=\"utf-8\") as f:\n",
    "    iliad = f.read()\n",
    "with open('Odyssey_lemmatized.txt', 'r', encoding=\"utf-8\") as f:\n",
    "    odyssey = f.read()"
   ],
   "id": "57acd1a71b634e01",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lemmatized_texts = []\n",
    "lemmatized_texts.extend(sorted(list(lemmatized_folder.glob('*'))))\n",
    "\n",
    "plato_works = {}\n",
    "\n",
    "for lemmatized_text in lemmatized_texts:\n",
    "    with open(lemmatized_text, 'r', encoding=\"utf-8\") as f:\n",
    "        l_t = f.read()\n",
    "    name = lemmatized_text.name\n",
    "    plato_works[name] = l_t"
   ],
   "id": "1dc311471b3ed11a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Bigrams",
   "id": "887420178f398030"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def compare_bigrams(target, comparison):\n",
    "    \"\"\"\n",
    "    checks for common bigrams\n",
    "    :param target: str, reference text\n",
    "    :param comparison: str, comparison text\n",
    "    :return: tuple of the form (common bigrams (Counter Object), number of common bigrams, number of comparison bigrams)\n",
    "    \"\"\"\n",
    "    p = PunktLanguageVars()\n",
    "    target = target.replace(',', '').replace('.', '').replace(':', '').replace(';', '')\n",
    "    target_bigrams = Counter(bigrams(p.word_tokenize(target)))\n",
    "    comparison = comparison.replace(',', '').replace('.', '').replace(':', '').replace(';', '')\n",
    "    comparison_bigrams = Counter(bigrams(p.word_tokenize(comparison)))\n",
    "    overlap = target_bigrams & comparison_bigrams\n",
    "    total_count = sum(overlap.values())\n",
    "    relative_count = total_count / sum(comparison_bigrams.values())\n",
    "    return overlap, total_count, relative_count\n"
   ],
   "id": "d24cd07cd8191537",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "iliad_plato_bigram_overlap = [[name, compare_bigrams(iliad, value)[0], compare_bigrams(iliad, value)[1], compare_bigrams(iliad, value)[2]] for name, value in plato_works.items()]\n",
    "data_bi_iliad = pd.DataFrame(iliad_plato_bigram_overlap)    \n",
    "data_bi_iliad"
   ],
   "id": "7a2a433d99231411",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plot = sns.barplot(x=data_bi_iliad.iloc[:, 0], y=data_bi_iliad.iloc[:, 3]*100)\n",
    "plot.set_xticks(range(len(data_bi_iliad.iloc[:, 0]))) \n",
    "plot.set_xticklabels(plot.get_xticklabels(), rotation=90, ha=\"right\")\n",
    "\n",
    "plot.set_title(\"Percentage of Bigram Overlap between the Iliad and Plato's work\")\n",
    "sns.despine()"
   ],
   "id": "6ca8bfa197c82ff9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "odyssey_plato_bigram_overlap = [[name, compare_bigrams(odyssey, value)[0], compare_bigrams(odyssey, value)[1], compare_bigrams(odyssey, value)[2]] for name, value in plato_works.items()]\n",
    "data_bi_odyssey = pd.DataFrame(odyssey_plato_bigram_overlap)    \n",
    "data_bi_odyssey"
   ],
   "id": "44ad93fb96dda231",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plot = sns.barplot(x=data_bi_odyssey.iloc[:, 0], y=data_bi_odyssey.iloc[:, 3]*100)\n",
    "plot.set_xticks(range(len(data_bi_odyssey.iloc[:, 0]))) \n",
    "plot.set_xticklabels(plot.get_xticklabels(), rotation=90, ha=\"right\")\n",
    "\n",
    "plot.set_title(\"Percentage of Bigram Overlap between the Odyssey and Plato's work\")\n",
    "sns.despine()"
   ],
   "id": "c1ef4c5d6cca0d3f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Trigrams\n",
   "id": "5e7265cb824b77d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def compare_trigrams(target, comparison):\n",
    "    \"\"\"\n",
    "    checks for common trigrams\n",
    "    :param target: str, reference text\n",
    "    :param comparison: str, comparison text\n",
    "    :return: tuple of the form (common trigrams (Counter Object), number of common trigrams, number of comparison trigrams)\n",
    "    \"\"\"\n",
    "    p = PunktLanguageVars()\n",
    "    target = target.replace(',', '').replace('.', '').replace(':', '').replace(';', '')\n",
    "    target_trigrams = Counter(trigrams(p.word_tokenize(target)))\n",
    "    comparison = comparison.replace(',', '').replace('.', '').replace(':', '').replace(';', '')\n",
    "    comparison_trigrams = Counter(trigrams(p.word_tokenize(comparison)))\n",
    "    overlap = target_trigrams & comparison_trigrams\n",
    "    total_count = sum(overlap.values())\n",
    "    relative_count = total_count / sum(comparison_trigrams.values())\n",
    "    return overlap, total_count, relative_count"
   ],
   "id": "d1fe09760ff34830",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "iliad_plato_trigram_overlap = [[name, compare_trigrams(iliad, value)[0], compare_trigrams(iliad, value)[1], compare_trigrams(iliad, value)[2]] for name, value in plato_works.items()]\n",
    "data_tri_iliad = pd.DataFrame(iliad_plato_trigram_overlap)    \n",
    "data_tri_iliad"
   ],
   "id": "7450c354f5643681",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plot = sns.barplot(x=data_tri_iliad.iloc[:, 0], y=data_tri_iliad.iloc[:, 3]*100)\n",
    "plot.set_xticks(range(len(data_tri_iliad.iloc[:, 0]))) \n",
    "plot.set_xticklabels(plot.get_xticklabels(), rotation=90, ha=\"right\")\n",
    "\n",
    "plot.set_title(\"Percentage of Trigram Overlap between the Iliad and Plato's work\")\n",
    "sns.despine()"
   ],
   "id": "5247669b291036ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "odyssey_plato_trigram_overlap = [[name, compare_trigrams(odyssey, value)[0], compare_trigrams(odyssey, value)[1], compare_trigrams(odyssey, value)[2]] for name, value in plato_works.items()]\n",
    "data_tri_odyssey = pd.DataFrame(odyssey_plato_trigram_overlap)    \n",
    "data_tri_odyssey"
   ],
   "id": "5a4a84484861f49d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plot = sns.barplot(x=data_tri_odyssey.iloc[:, 0], y=data_tri_odyssey.iloc[:, 3]*100)\n",
    "plot.set_xticks(range(len(data_tri_odyssey.iloc[:, 0]))) \n",
    "plot.set_xticklabels(plot.get_xticklabels(), rotation=90, ha=\"right\")\n",
    "\n",
    "plot.set_title(\"Percentage of Trigram Overlap between the Odyssey and Plato's work\")\n",
    "sns.despine()"
   ],
   "id": "49d9d96f1fbdaad6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Let's look which sentences (measured by bi/trigrams) are similar",
   "id": "eba819c899398b46"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def make_sentences(text):\n",
    "    \"\"\"\n",
    "    Turns a text in a list of sentences. Note that Ancient Greek uses different punctuation! \n",
    "    :param text: str\n",
    "    :return: list of strings\n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    sentence = \"\"\n",
    "    \n",
    "    text = text.replace('.', ' .').replace(';', ' ;')\n",
    "    tokens = text.split()\n",
    "    for word in tokens:\n",
    "        if word in [';', '.']:\n",
    "            if sentence:\n",
    "                sentences.append(sentence[:-1])\n",
    "                sentence = \"\"\n",
    "        else:\n",
    "            sentence += word+\" \"\n",
    "    return sentences"
   ],
   "id": "22b6bd6958c218cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "iliad_sentences = make_sentences(iliad)\n",
    "\n",
    "odyssey_sentences = make_sentences(odyssey)\n",
    "\n",
    "plato_sentences = []\n",
    "for work in plato_works:\n",
    "    sentences = make_sentences(plato_works[work])\n",
    "    for line in sentences:\n",
    "        plato_sentences.append([line, work])"
   ],
   "id": "86be835c12f10024",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def make_bg_list(sentence):\n",
    "    \"\"\"\n",
    "    computes all bigrams in a sentence.\n",
    "    :param sentence: str,\n",
    "    :return: list of bigrams\n",
    "    \"\"\"\n",
    "    p = PunktLanguageVars()\n",
    "    return list(bigrams(p.word_tokenize(sentence)))"
   ],
   "id": "9bb60f5931f43c21",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "iliad_sentences_with_bigram = []\n",
    "for s in iliad_sentences:\n",
    "    iliad_sentences_with_bigram.append([make_bg_list(s), s])\n",
    "\n",
    "odyssey_sentences_with_bigram = []\n",
    "for s in odyssey_sentences:\n",
    "    odyssey_sentences_with_bigram.append([make_bg_list(s), s])\n",
    "\n",
    "plato_sentences_with_bigram = []\n",
    "for s in plato_sentences:\n",
    "    if make_bg_list(s[0]):\n",
    "        plato_sentences_with_bigram.append([make_bg_list(s[0]), s[0], s[1]])"
   ],
   "id": "941ff7a57db002f8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Comparison Iliad",
   "id": "8825b0406166aeae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "iliad_bigram_sets = [set(row[0]) for row in iliad_sentences_with_bigram]\n",
    "plato_bigram_sets = [set(row[0]) for row in plato_sentences_with_bigram]\n",
    "\n",
    "ScoreMatrix = numpy.zeros((len(iliad_sentences_with_bigram), len(plato_sentences_with_bigram)))\n",
    "\n",
    "for i, iliad_bigrams in enumerate(iliad_bigram_sets):\n",
    "    for j, plato_bigrams in enumerate(plato_bigram_sets):\n",
    "        ScoreMatrix[i, j] = len(iliad_bigrams & plato_bigrams) "
   ],
   "id": "f1f2ea49aa312acb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "row_sums = numpy.sum(ScoreMatrix , axis=1)\n",
    "top_10_indices = numpy.argsort(row_sums)[-10:][::-1]\n",
    "top_10_rows = ScoreMatrix[top_10_indices]\n",
    "top_5_indices_per_row = numpy.argsort(top_10_rows, axis=1)[:, -5:][:, ::-1]\n",
    "\n",
    "# Output\n",
    "print(\"Indices of the top 5 values in each of the top 10 rows:\")\n",
    "for i, indices in enumerate(top_10_indices):\n",
    "    print('\\nSentence in the Iliad')\n",
    "    print(iliad_sentences_with_bigram[indices][1])\n",
    "    print(\"\\nSimilar Sentences in Plato's works\")\n",
    "    for j in top_5_indices_per_row[i,:]:\n",
    "        print(plato_sentences_with_bigram[j][1:])\n"
   ],
   "id": "38002295644e4b2f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Comparison Odyssey",
   "id": "eb6600c6354e19a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "odyssey_bigram_sets = [set(row[0]) for row in odyssey_sentences_with_bigram]\n",
    "plato_bigram_sets = [set(row[0]) for row in plato_sentences_with_bigram]\n",
    "\n",
    "ScoreMatrix = numpy.zeros((len(odyssey_sentences_with_bigram), len(plato_sentences_with_bigram)))\n",
    "\n",
    "for i, odyssey_bigrams in enumerate(odyssey_bigram_sets):\n",
    "    for j, plato_bigrams in enumerate(plato_bigram_sets):\n",
    "        ScoreMatrix[i, j] = len(odyssey_bigrams & plato_bigrams)   "
   ],
   "id": "8874c0abaa71f7cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "row_sums = numpy.sum(ScoreMatrix , axis=1)\n",
    "top_10_indices = numpy.argsort(row_sums)[-10:][::-1]\n",
    "top_10_rows = ScoreMatrix[top_10_indices]\n",
    "top_5_indices_per_row = numpy.argsort(top_10_rows, axis=1)[:, -5:][:, ::-1]\n",
    "\n",
    "# Output\n",
    "print(\"Indices of the top 5 values in each of the top 10 rows:\")\n",
    "for i, indices in enumerate(top_10_indices):\n",
    "    print('\\nSentence in the Odyssey')\n",
    "    print(iliad_sentences_with_bigram[indices][1])\n",
    "    print(\"\\nSimilar Sentences in Plato's works\")\n",
    "    for j in top_5_indices_per_row[i,:]:\n",
    "        print(plato_sentences_with_bigram[j][1:])"
   ],
   "id": "a505ba84bcb67655",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
